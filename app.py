import os
import re
import struct
import time
import uuid
import shutil
import logging
import threading
import mimetypes  # <--- Ø§ÛŒÙ† Ø®Ø· Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª
from fastapi import FastAPI, HTTPException, Body, Request
from fastapi.responses import FileResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from google import genai
from google.genai import types

try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False

# --- Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù„Ø§Ú¯ÛŒÙ†Ú¯ ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

# --- Ù…Ù†Ø·Ù‚ Ù…Ø¯ÛŒØ±ÛŒØª API Key (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
ALL_API_KEYS: list[str] = []
NEXT_KEY_INDEX: int = 0
KEY_LOCK: threading.Lock = threading.Lock()

def _init_api_keys():
    global ALL_API_KEYS
    all_keys_string = os.environ.get("ALL_GEMINI_API_KEYS")
    if all_keys_string:
        ALL_API_KEYS = [key.strip() for key in all_keys_string.split(',') if key.strip()]
    logging.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(ALL_API_KEYS)} Ú©Ù„ÛŒØ¯ API Ø¬ÛŒÙ…ÛŒÙ†Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
    if not ALL_API_KEYS:
        logging.warning("â›”ï¸ Ø®Ø·Ø§ÛŒ Ø­ÛŒØ§ØªÛŒ: Ù‡ÛŒÚ† Secret Ø¨Ø§ Ù†Ø§Ù… ALL_GEMINI_API_KEYS ÛŒØ§ÙØª Ù†Ø´Ø¯!")

_init_api_keys()

def get_next_api_key():
    global NEXT_KEY_INDEX, ALL_API_KEYS, KEY_LOCK
    with KEY_LOCK:
        if not ALL_API_KEYS: return None, None
        key_to_use = ALL_API_KEYS[NEXT_KEY_INDEX % len(ALL_API_KEYS)]
        key_display_index = (NEXT_KEY_INDEX % len(ALL_API_KEYS)) + 1
        NEXT_KEY_INDEX += 1
        return key_to_use, key_display_index

# --- Ø«Ø§Ø¨Øªâ€ŒÙ‡Ø§ Ùˆ ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
FIXED_MODEL_NAME = "gemini-2.5-flash-preview-tts"
DEFAULT_MAX_CHUNK_SIZE = 3800
DEFAULT_SLEEP_BETWEEN_REQUESTS = 8

def save_binary_file(file_name, data):
    try:
        with open(file_name, "wb") as f: f.write(data)
        return file_name
    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ {file_name}: {e}")
        return None

def convert_to_wav(audio_data: bytes, mime_type: str) -> bytes:
    parameters = parse_audio_mime_type(mime_type)
    bits_per_sample, rate = parameters["bits_per_sample"], parameters["rate"]
    num_channels, data_size = 1, len(audio_data)
    bytes_per_sample, block_align = bits_per_sample // 8, num_channels * (bits_per_sample // 8)
    byte_rate, chunk_size = rate * block_align, 36 + data_size
    header = struct.pack("<4sI4s4sIHHIIHH4sI", b"RIFF", chunk_size, b"WAVE", b"fmt ", 16, 1, num_channels, rate, byte_rate, block_align, bits_per_sample, b"data", data_size)
    return header + audio_data

def parse_audio_mime_type(mime_type: str) -> dict[str, int]:
    bits, rate = 16, 24000
    for param in mime_type.split(";"):
        param = param.strip()
        if param.lower().startswith("rate="):
            try: rate = int(param.split("=", 1)[1])
            except: pass
        elif param.startswith("audio/L"):
            try: bits = int(param.split("L", 1)[1])
            except: pass
    return {"bits_per_sample": bits, "rate": rate}

def smart_text_split(text, max_size=3800):
    if len(text) <= max_size: return [text]
    chunks, current_chunk = [], ""
    sentences = re.split(r'(?<=[.!?ØŸ])\s+', text)
    for sentence in sentences:
        if len(current_chunk) + len(sentence) + 1 > max_size:
            if current_chunk: chunks.append(current_chunk.strip())
            current_chunk = sentence
            while len(current_chunk) > max_size:
                split_idx = next((i for i in range(max_size - 1, max_size // 2, -1) if current_chunk[i] in ['ØŒ', ',', ';', ':', ' ']), -1)
                part, current_chunk = (current_chunk[:split_idx+1], current_chunk[split_idx+1:]) if split_idx != -1 else (current_chunk[:max_size], current_chunk[max_size:])
                chunks.append(part.strip())
        else: current_chunk += (" " if current_chunk else "") + sentence
    if current_chunk: chunks.append(current_chunk.strip())
    final_chunks = [c for c in chunks if c]
    return final_chunks

def merge_audio_files_func(file_paths, output_path):
    if not PYDUB_AVAILABLE: logging.warning("âš ï¸ pydub Ø¨Ø±Ø§ÛŒ Ø§Ø¯ØºØ§Ù… Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."); return False
    try:
        combined = AudioSegment.empty()
        for i, fp in enumerate(file_paths):
            if os.path.exists(fp): combined += AudioSegment.from_file(fp) + (AudioSegment.silent(duration=150) if i < len(file_paths) - 1 else AudioSegment.empty())
            else: logging.warning(f"âš ï¸ ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§Ø¯ØºØ§Ù… Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {fp}")
        combined.export(output_path, format="wav")
        return True
    except Exception as e: logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¯ØºØ§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ: {e}"); return False

# --- Ù…Ù†Ø·Ù‚ ØªÙˆÙ„ÛŒØ¯ ØµØ¯Ø§ Ø¨Ø§ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
def generate_audio_chunk_with_retry(chunk_text, prompt_text, voice, temp, session_id):
    if not ALL_API_KEYS:
        logging.error(f"[{session_id}] âŒ Ù‡ÛŒÚ† Ú©Ù„ÛŒØ¯ API Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØµØ¯Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
        return None
    for _ in range(len(ALL_API_KEYS)):
        selected_api_key, key_idx_display = get_next_api_key()
        if not selected_api_key: break
        logging.info(f"[{session_id}] âš™ï¸ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù‚Ø·Ø¹Ù‡ Ø¨Ø§ Ú©Ù„ÛŒØ¯ API Ø´Ù…Ø§Ø±Ù‡ {key_idx_display} (...{selected_api_key[-4:]})")
        try:
            client = genai.Client(api_key=selected_api_key)
            final_text = f'"{prompt_text}"\n{chunk_text}' if prompt_text and prompt_text.strip() else chunk_text
            contents = [types.Content(role="user", parts=[types.Part.from_text(text=final_text)])]
            config = types.GenerateContentConfig(temperature=temp, response_modalities=["audio"],
                speech_config=types.SpeechConfig(voice_config=types.VoiceConfig(
                    prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name=voice))))
            response = client.models.generate_content(model=FIXED_MODEL_NAME, contents=contents, config=config)
            if response.candidates and response.candidates[0].content and response.candidates[0].content.parts and response.candidates[0].content.parts[0].inline_data:
                logging.info(f"[{session_id}] âœ… Ù‚Ø·Ø¹Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙˆØ³Ø· Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ {key_idx_display} ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")
                return response.candidates[0].content.parts[0].inline_data
            else:
                logging.warning(f"[{session_id}] âš ï¸ Ù¾Ø§Ø³Ø® API Ø¨Ø±Ø§ÛŒ Ù‚Ø·Ø¹Ù‡ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ {key_idx_display} Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ ØµÙˆØªÛŒ Ø¨ÙˆØ¯.")
        except Exception as e:
            logging.error(f"[{session_id}] âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù‚Ø·Ø¹Ù‡ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ {key_idx_display}: {e}.")
    return None

def core_generate_audio(text_input, prompt_input, selected_voice, temperature_val, session_id):
    logging.info(f"[{session_id}] ğŸš€ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆÙ„ÛŒØ¯ ØµØ¯Ø§.")
    temp_dir = f"temp_{session_id}"
    os.makedirs(temp_dir, exist_ok=True)
    output_base_name = f"{temp_dir}/audio_session_{session_id}"
    if not text_input or not text_input.strip():
        raise ValueError("Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")

    text_chunks = smart_text_split(text_input, DEFAULT_MAX_CHUNK_SIZE)
    if not text_chunks:
        raise ValueError("Ù…ØªÙ† Ù‚Ø§Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡ Ù‚Ø·Ø¹Ø§Øª Ú©ÙˆÚ†Ú©ØªØ± Ù†ÛŒØ³Øª.")

    generated_files = []
    final_audio_file = None
    try:
        for i, chunk in enumerate(text_chunks):
            logging.info(f"[{session_id}] ğŸ”Š Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‚Ø·Ø¹Ù‡ {i+1}/{len(text_chunks)}...")
            inline_data = generate_audio_chunk_with_retry(chunk, prompt_input, selected_voice, temperature_val, session_id)
            if inline_data:
                data_buffer = inline_data.data
                ext = mimetypes.guess_extension(inline_data.mime_type) or ".wav"
                if "audio/L" in inline_data.mime_type and ext == ".wav": 
                    data_buffer = convert_to_wav(data_buffer, inline_data.mime_type)
                if not ext.startswith("."): ext = "." + ext
                fpath = save_binary_file(f"{output_base_name}_part{i+1:03d}{ext}", data_buffer)
                if fpath: generated_files.append(fpath)
            else:
                raise Exception(f"ÙØ±Ø¢ÛŒÙ†Ø¯ Ù…ØªÙˆÙ‚Ù Ø´Ø¯ Ø²ÛŒØ±Ø§ ØªÙˆÙ„ÛŒØ¯ Ù‚Ø·Ø¹Ù‡ {i+1} Ø¨Ø§ ØªÙ…Ø§Ù… Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
            if i < len(text_chunks) - 1: time.sleep(DEFAULT_SLEEP_BETWEEN_REQUESTS)

        if not generated_files:
            raise Exception("Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯.")
        
        final_output_path = f"output_{session_id}.wav"
        if len(generated_files) > 1:
            if PYDUB_AVAILABLE and merge_audio_files_func(generated_files, final_output_path):
                final_audio_file = final_output_path
            else:
                shutil.move(generated_files[0], final_output_path)
                final_audio_file = final_output_path
        else:
            shutil.move(generated_files[0], final_output_path)
            final_audio_file = final_output_path
        
        logging.info(f"[{session_id}] âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: {os.path.basename(final_audio_file)}")
        return final_audio_file
    finally:
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
            logging.info(f"[{session_id}] ğŸ§¹ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ù…ÙˆÙ‚Øª '{temp_dir}' Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø´Ø¯.")


# --- FastAPI App ---
app = FastAPI(title="Alpha TTS API")

# Ø§ÛŒÙ† Ø¨Ø®Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§ØªÛŒÚ© Ø´Ù…Ø§ (index.html, css, js) Ø±Ø§ Ø³Ø±Ùˆ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
# ØªØºÛŒÛŒØ±: Ù†Ø§Ù… Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ø±Ø§ Ø¨Ù‡ "public" ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯ÛŒÙ… ØªØ§ Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± ÙØ§ÛŒÙ„ Ø´Ù…Ø§ Ù…Ø·Ø§Ø¨Ù‚Øª Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.
app.mount("/static", StaticFiles(directory="public", html=True), name="static")


# Ù…Ø¯Ù„ ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ API
class TTSRequest(BaseModel):
    text: str
    prompt: str | None = ""
    speaker: str
    temperature: float

@app.post("/api/generate-audio")
async def generate_audio_endpoint(request: TTSRequest):
    session_id = str(uuid.uuid4())[:8]
    logging.info(f"[{session_id}] ğŸ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¬Ø¯ÛŒØ¯ API Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
    try:
        if not request.text.strip():
            raise HTTPException(status_code=400, detail="Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯.")
        
        final_path = core_generate_audio(
            text_input=request.text,
            prompt_input=request.prompt,
            selected_voice=request.speaker,
            temperature_val=request.temperature,
            session_id=session_id
        )
        if final_path and os.path.exists(final_path):
            # Ù¾Ø³ Ø§Ø² Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„ØŒ Ø¢Ù† Ø±Ø§ Ù¾Ø§Ú© Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ ÙØ¶Ø§ Ø§Ø´ØºØ§Ù„ Ù†Ø´ÙˆØ¯
            return FileResponse(path=final_path, media_type='audio/wav', filename=os.path.basename(final_path), background=shutil.rmtree(os.path.dirname(final_path), ignore_errors=True))
        else:
            raise HTTPException(status_code=500, detail="Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¯Ø± Ø³Ø±ÙˆØ±.")
    except Exception as e:
        logging.error(f"[{session_id}] âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± API: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Ø§ÛŒÙ† Ø¨Ø®Ø´ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ (index.html) Ø±Ø§ Ø¯Ø± Ø±ÙˆØª Ø§ØµÙ„ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
@app.get("/", response_class=HTMLResponse)
@app.head("/", response_class=HTMLResponse) # <-- Ø§ÛŒÙ† Ø®Ø· Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
async def read_root():
    # ... (Ù…Ø­ØªÙˆØ§ÛŒ ØªØ§Ø¨Ø¹ ØªØºÛŒÛŒØ±ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯)
    # ØªØºÛŒÛŒØ±: Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø±Ø§ Ø¨Ù‡ "public/index.html" ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯ÛŒÙ…
    with open("public/index.html", "r", encoding="utf-8") as f:
        html_content = f.read()
    return HTMLResponse(content=html_content)
