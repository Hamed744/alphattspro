import base64
import mimetypes
import os
import re
import struct
import time
import uuid
import shutil
import json
import sys
import logging
import threading

# Import the Google Generative AI library components
try:
    import google.generativeai as genai
    from google.generativeai import types  # Ù‡Ù†ÙˆØ² Ø¨Ø±Ø§ÛŒ GenerationConfig Ø¨Ù‡ Ø¢Ù† Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒÙ…
    GOOGLE_API_AVAILABLE = True
except ImportError:
    GOOGLE_API_AVAILABLE = False

try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False

# --- Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù„Ø§Ú¯ÛŒÙ†Ú¯ ---
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] - [Python Worker] - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    stream=sys.stdout
)

# --- Ù…Ø¯ÛŒØ±ÛŒØª API Key ---
ALL_API_KEYS: list[str] = []
NEXT_KEY_INDEX: int = 0
KEY_LOCK: threading.Lock = threading.Lock()

def _init_api_keys():
    global ALL_API_KEYS
    all_keys_string = os.environ.get("ALL_GEMINI_API_KEYS")
    if all_keys_string:
        ALL_API_KEYS = [key.strip() for key in all_keys_string.split(',') if key.strip()]
    if ALL_API_KEYS:
        logging.info(f"âœ… Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÙˆÙÙ‚ {len(ALL_API_KEYS)} Ú©Ù„ÛŒØ¯ API Ø¬ÛŒÙ…ÛŒÙ†Ø§ÛŒ.")
    else:
        logging.warning("â›”ï¸ Ø®Ø·Ø§ÛŒ Ø­ÛŒØ§ØªÛŒ: Ù‡ÛŒÚ† Ú©Ù„ÛŒØ¯ API Ø¯Ø± Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ 'ALL_GEMINI_API_KEYS' ÛŒØ§ÙØª Ù†Ø´Ø¯!")

def get_next_api_key():
    global NEXT_KEY_INDEX, ALL_API_KEYS, KEY_LOCK
    with KEY_LOCK:
        if not ALL_API_KEYS:
            return None, None
        key_to_use = ALL_API_KEYS[NEXT_KEY_INDEX % len(ALL_API_KEYS)]
        key_display_index = (NEXT_KEY_INDEX % len(ALL_API_KEYS)) + 1
        NEXT_KEY_INDEX += 1
        return key_to_use, key_display_index

# --- Ø«Ø§Ø¨Øªâ€ŒÙ‡Ø§ Ùˆ ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
FIXED_MODEL_NAME = "gemini-2.5-flash-preview-tts"
# ... (ØªÙ…Ø§Ù… ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ save_binary_file, convert_to_wav, parse_audio_mime_type, smart_text_split, merge_audio_files_func Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯) ...
def save_binary_file(file_name, data):
    try:
        with open(file_name, "wb") as f: f.write(data)
        return file_name
    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ {file_name}: {e}")
        return None
def convert_to_wav(audio_data: bytes, mime_type: str) -> bytes:
    parameters = parse_audio_mime_type(mime_type)
    bits_per_sample, rate = parameters["bits_per_sample"], parameters["rate"]
    num_channels, data_size = 1, len(audio_data)
    bytes_per_sample, block_align = bits_per_sample // 8, num_channels * (bits_per_sample // 8)
    byte_rate, chunk_size = rate * block_align, 36 + data_size
    header = struct.pack("<4sI4s4sIHHIIHH4sI", b"RIFF", chunk_size, b"WAVE", b"fmt ", 16, 1, num_channels, rate, byte_rate, block_align, bits_per_sample, b"data", data_size)
    return header + audio_data
def parse_audio_mime_type(mime_type: str) -> dict[str, int]:
    bits, rate = 16, 24000
    for param in mime_type.split(";"):
        param = param.strip()
        if param.lower().startswith("rate="):
            try: rate = int(param.split("=", 1)[1])
            except: pass
        elif param.startswith("audio/L"):
            try: bits = int(param.split("L", 1)[1])
            except: pass
    return {"bits_per_sample": bits, "rate": rate}
def smart_text_split(text, max_size=3800):
    if len(text) <= max_size: return [text]
    chunks, current_chunk = [], ""
    sentences = re.split(r'(?<=[.!?ØŸ])\s+', text)
    for sentence in sentences:
        if len(current_chunk) + len(sentence) + 1 > max_size:
            if current_chunk: chunks.append(current_chunk.strip())
            current_chunk = sentence
            while len(current_chunk) > max_size:
                split_idx = next((i for i in range(max_size - 1, max_size // 2, -1) if current_chunk[i] in ['ØŒ', ',', ';', ':', ' ']), -1)
                part, current_chunk = (current_chunk[:split_idx+1], current_chunk[split_idx+1:]) if split_idx != -1 else (current_chunk[:max_size], current_chunk[max_size:])
                chunks.append(part.strip())
        else: current_chunk += (" " if current_chunk else "") + sentence
    if current_chunk: chunks.append(current_chunk.strip())
    final_chunks = [c for c in chunks if c]
    return final_chunks
def merge_audio_files_func(file_paths, output_path):
    if not PYDUB_AVAILABLE:
        logging.warning("âš ï¸ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ pydub Ø¨Ø±Ø§ÛŒ Ø§Ø¯ØºØ§Ù… Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
        return False
    try:
        combined = AudioSegment.empty()
        for i, fp in enumerate(file_paths):
            if os.path.exists(fp):
                combined += AudioSegment.from_file(fp) + (AudioSegment.silent(duration=150) if i < len(file_paths) - 1 else AudioSegment.empty())
            else:
                logging.warning(f"âš ï¸ ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§Ø¯ØºØ§Ù… Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {fp}")
        combined.export(output_path, format="wav")
        return True
    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¯ØºØ§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ: {e}")
        return False
# --- END: ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---

# --- START: Ù…Ù†Ø·Ù‚ ØªÙˆÙ„ÛŒØ¯ ØµØ¯Ø§ Ø¨Ø§ API Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ ---
def generate_audio_chunk_with_retry(chunk_text, prompt_text, voice, temp, session_id):
    """
    ÛŒÚ© Ù‚Ø·Ø¹Ù‡ ØµÙˆØªÛŒ Ø±Ø§ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ùˆ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² API Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    if not ALL_API_KEYS:
        logging.error(f"[{session_id}] âŒ Ù‡ÛŒÚ† Ú©Ù„ÛŒØ¯ API Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØµØ¯Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
        return None, "Ù‡ÛŒÚ† Ú©Ù„ÛŒØ¯ API Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

    last_error = "Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ"

    for i in range(len(ALL_API_KEYS)):
        selected_api_key, key_idx_display = get_next_api_key()
        if not selected_api_key:
            logging.warning(f"[{session_id}] âš ï¸ get_next_api_key Ù‡ÛŒÚ† Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ù†Ú¯Ø±Ø¯Ø§Ù†Ø¯.")
            continue
        
        logging.info(f"[{session_id}] âš™ï¸ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù‚Ø·Ø¹Ù‡ Ø¨Ø§ Ú©Ù„ÛŒØ¯ API Ø´Ù…Ø§Ø±Ù‡ {key_idx_display} (...{selected_api_key[-4:]})")
        
        try:
            genai.configure(api_key=selected_api_key)
            final_text = f'"{prompt_text}"\n{chunk_text}' if prompt_text and prompt_text.strip() else chunk_text
            
            # **ØªØºÛŒÛŒØ± Ø§ØµÙ„ÛŒ Ø§ÛŒÙ†Ø¬Ø§Ø³Øª**
            # Ø¨Ù‡ Ø¬Ø§ÛŒ `SpeechConfig`ØŒ Ù…Ø§ Ø§Ø² `tts_request` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….
            tts_request = genai.protos.SynthesizeSpeechRequest(
                text=final_text,
                voice=genai.protos.Voice(name=voice),
                audio_config=genai.protos.AudioConfig(
                    audio_encoding="LINEAR16",  # Ø®Ø±ÙˆØ¬ÛŒ WAV
                    sample_rate_hertz=24000
                ),
            )

            # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…Ø¯Ù„ Ø¨Ù‡ Ø±ÙˆØ´ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ TTS
            # Ù…Ø§ Ø§Ø² `GenerativeModel` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø§Ù…Ø§ Ù…Ø­ØªÙˆØ§ Ø±Ø§ Ø¨Ù‡ Ø´Ú©Ù„ Ø®Ø§Øµâ€ŒØªØ±ÛŒ Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ….
            # Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§ÛŒÙ†Ú©Ù‡ Ù…Ø¯Ù„ Ø´Ù…Ø§ `gemini-2.5-flash-preview-tts` Ø§Ø³ØªØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù‡Ù…Ú†Ù†Ø§Ù† Ø§Ø² `generate_content` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ø¯.
            # Ø¨ÛŒØ§ÛŒÛŒØ¯ Ø±ÙˆØ´ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ØªØ± `text-to-speech` Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒÙ… Ø§Ú¯Ø± Ù…Ø¯Ù„ Ø¢Ù† Ø±Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú©Ù†Ø¯.
            # Ø§Ú¯Ø± Ø§ÛŒÙ† Ú©Ø§Ø± Ù†Ú©Ø±Ø¯ØŒ Ø¨Ù‡ Ø±ÙˆØ´ `generate_content` Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯ÛŒÙ….
            
            # Ø±ÙˆÛŒÚ©Ø±Ø¯ Û±: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² API Ù…Ø®ØµÙˆØµ TTS (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯)
            # Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ú©ÛŒÙˆÙ…Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ØªØ± Ø§Ø³Øª.
            # model = genai.GenerativeModel(model_name=FIXED_MODEL_NAME)
            # response = model.synthesize_speech(request=tts_request)
            
            # **Ø±ÙˆÛŒÚ©Ø±Ø¯ Û²: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² `generate_content` Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ (Ø³Ø§Ø²Ú¯Ø§Ø±ØªØ± Ø¨Ø§ Ú©Ø¯ Ù‚Ø¨Ù„ÛŒ)**
            model = genai.GenerativeModel(model_name=FIXED_MODEL_NAME)
            
            # Ù…Ø§ `temperature` Ø±Ø§ Ø¯Ø± `generation_config` Ùˆ `voice` Ø±Ø§ Ø¯Ø± Ø®ÙˆØ¯ Ù…ØªÙ† Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ….
            # Ø§ÛŒÙ† Ø±ÙˆØ´ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ØªØ± Ø¬ÙˆØ§Ø¨ Ø¯Ù‡Ø¯.
            # Ø§Ù…Ø§ Ø±ÙˆØ´ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ `voice_name` Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù¾Ø§Ø±Ø§Ù…ØªØ±ÛŒ Ø¬Ø¯Ø§ Ø¨ÙØ±Ø³ØªÛŒÙ….
            
            # **Ø§ØµÙ„Ø§Ø­ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ ØµØ­ÛŒØ­ Ø¨Ø± Ø§Ø³Ø§Ø³ API ÙØ¹Ù„ÛŒ:**
            # `SpeechConfig` Ø¯ÛŒÚ¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. `voice` Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ù¾Ø§Ø±Ø§Ù…ØªØ± Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ù‡ `generate_content` Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.
            # Ø¨Ù„Ú©Ù‡ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù…Ø­ØªÙˆØ§ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
            # Ø¨ÛŒØ§ÛŒÛŒØ¯ Ø¨Ù‡ Ø³Ø§Ø®ØªØ§Ø± Ø§ØµÙ„ÛŒ Gradio Ø´Ù…Ø§ Ø¨Ø±Ú¯Ø±Ø¯ÛŒÙ… Ùˆ Ø¨Ø¨ÛŒÙ†ÛŒÙ… Ú†Ú¯ÙˆÙ†Ù‡ Ø¢Ù† Ø±Ø§ ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‡ÛŒÙ….
            # Ú©Ø¯ Gradio Ø´Ù…Ø§ Ø§Ø² `genai.Client` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ø±Ø¯ Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª ÛŒÚ© wrapper Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø¨Ø§Ø´Ø¯.
            # Ø¯Ø± `google-generativeai` Ù…Ø¯Ø±Ù†ØŒ Ø±ÙˆØ´ Ú©Ø§Ø± Ù…ØªÙØ§ÙˆØª Ø§Ø³Øª.

            # **Ú©Ø¯ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ:**
            # Ù…Ø§ ØªÙ…Ø§Ù… ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø§ Ø¯Ø± `generation_config` Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
            generation_config = types.GenerationConfig(
                temperature=temp,
                response_mime_type="audio/wav"
            )

            # Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ Ú©Ù‡ Ø¨Ù‡ Ù…Ø¯Ù„ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
            contents = [{"role": "user", "parts": [{"text": final_text}]}]
            
            # Ø­Ø§Ù„Ø§ Ù…Ø¯Ù„ Ø±Ø§ Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ…ØŒ Ø§Ù…Ø§ Ø¨Ø§ voice_name Ø¯Ø± Ù†Ø§Ù… Ù…Ø¯Ù„!
            # Ø§ÛŒÙ† Ø±ÙˆØ´ÛŒ Ø§Ø³Øª Ú©Ù‡ Ú¯ÙˆÚ¯Ù„ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ TTS Ø¬Ø¯ÛŒØ¯ØªØ± ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
            # Ù…Ø«Ø§Ù„: 'models/text-to-speech-en-us-1'
            # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ø´Ù…Ø§ØŒ Ù†Ø§Ù… ØµØ¯Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ù‡ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
            # Ù…Ø«Ù„Ø§: "models/tts-1"
            # Ø§Ù…Ø§ Ú†ÙˆÙ† Ø´Ù…Ø§ ÛŒÚ© Ù…Ø¯Ù„ preview Ø¯Ø§Ø±ÛŒØ¯ØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø±ÙˆØ´ Ù…ØªÙØ§ÙˆØª Ø¨Ø§Ø´Ø¯.
            # Ø¨ÛŒØ§ÛŒÛŒØ¯ ÙØ±Ø¶ Ú©Ù†ÛŒÙ… `voice` Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ Ù†Ø­ÙˆÛŒ Ø¯Ø± `request_options` ÛŒØ§ Ø¬Ø§ÛŒ Ø¯ÛŒÚ¯Ø±ÛŒ Ø¨Ø§Ø´Ø¯.
            
            # **Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒÙ† Ø±Ø§Ù‡ Ù…Ù…Ú©Ù† Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ú©Ø§Ø± Ú©Ù†Ø¯:**
            # Ø¨ÛŒØ§ÛŒÛŒØ¯ ÙØ±Ø¶ Ú©Ù†ÛŒÙ… `voice` Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ù¾Ø§Ø±Ø§Ù…ØªØ± Ø¯Ø± `generation_config` ÛŒØ§ `request_options` Ù¾Ø°ÛŒØ±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
            # Ø§Ú¯Ø± Ø§ÛŒÙ† Ù‡Ù… Ú©Ø§Ø± Ù†Ú©Ø±Ø¯ØŒ ÛŒØ¹Ù†ÛŒ Ù…Ø¯Ù„ `gemini-2.5-flash-preview-tts` Ø¯ÛŒÚ¯Ø± Ø¨Ù‡ Ø§ÛŒÙ† Ø´Ú©Ù„ Ù‚Ø§Ø¨Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†ÛŒØ³Øª.

            # **Ø¢Ø®Ø±ÛŒÙ† ØªÙ„Ø§Ø´ Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± ØµØ­ÛŒØ­:**
            model = genai.GenerativeModel(FIXED_MODEL_NAME)
            response = model.generate_content(
                contents=contents,
                generation_config=generation_config
                # Ù‡ÛŒÚ† Ù¾Ø§Ø±Ø§Ù…ØªØ±ÛŒ Ø¨Ù‡ Ù†Ø§Ù… `voice` ÛŒØ§ `speech_config` Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.
                # `voice_name` Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ø¬Ø§ÛŒ Ø¯ÛŒÚ¯Ø±ÛŒ Ù…Ø´Ø®Øµ Ø´ÙˆØ¯.
                # Ø¯Ø± Ø¯Ø§Ú©ÛŒÙˆÙ…Ù†Øª Ø¬Ø¯ÛŒØ¯ Ú¯ÙˆÚ¯Ù„ØŒ voice name Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù†Ø§Ù… Ù…Ø¯Ù„ Ø§Ø³ØªØŒ Ù…Ø«Ù„Ø§Ù‹:
                # `genai.GenerativeModel('models/tts-1-hd')`
                # Ø¨ÛŒØ§ÛŒÛŒØ¯ ÙØ±Ø¶ Ú©Ù†ÛŒÙ… Ù…Ø¯Ù„ Ø´Ù…Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø² ÛŒÚ© voice Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ `voice` Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ø´Ù…Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
                # ÛŒØ§ Ø§ÛŒÙ†Ú©Ù‡ voice Ø¨Ø§ÛŒØ¯ Ø¯Ø± prompt Ø¨Ø§Ø´Ø¯.
                # Ù…Ø§ prompt Ø±Ø§ Ø¯Ø± Ù…ØªÙ† Ø¯Ø§Ø±ÛŒÙ…ØŒ Ù¾Ø³ Ø§ÛŒÙ† Ø¨Ø§ÛŒØ¯ Ú©Ø§ÙÛŒ Ø¨Ø§Ø´Ø¯.
                
                # Ø¨ÛŒØ§ÛŒÛŒØ¯ ÛŒÚ© Ø¨Ø§Ø± Ø¯ÛŒÚ¯Ø± Ú©Ø¯ Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒÙ…ØŒ Ø§Ù…Ø§ Ø§ÛŒÙ† Ø¨Ø§Ø± Ø¨Ø¯ÙˆÙ† `types.SpeechConfig` Ú©Ù‡ Ø®Ø·Ø§ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
            )

            if response.candidates and response.candidates[0].content and response.candidates[0].content.parts and response.candidates[0].content.parts[0].inline_data:
                logging.info(f"[{session_id}] âœ… Ù‚Ø·Ø¹Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙˆØ³Ø· Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ {key_idx_display} ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")
                return response.candidates[0].content.parts[0].inline_data, None
            else:
                logging.warning(f"[{session_id}] âš ï¸ Ù¾Ø§Ø³Ø® API Ø¨Ø±Ø§ÛŒ Ù‚Ø·Ø¹Ù‡ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ {key_idx_display} Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ ØµÙˆØªÛŒ Ø¨ÙˆØ¯. Ù¾Ø§Ø³Ø®: {response}")
                last_error = f"Ù¾Ø§Ø³Ø® API Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ {key_idx_display} Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ ØµÙˆØªÛŒ Ø¨ÙˆØ¯."
        
        except Exception as e:
            logging.error(f"[{session_id}] âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù‚Ø·Ø¹Ù‡ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ {key_idx_display}. Ø®Ø·Ø§ÛŒ API: {e}.")
            last_error = str(e)
            
    logging.error(f"[{session_id}] âŒ ØªÙ…Ø§Ù… Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API Ø§Ù…ØªØ­Ø§Ù† Ø´Ø¯Ù†Ø¯ Ø§Ù…Ø§ Ù‡ÛŒÚ†â€ŒÚ©Ø¯Ø§Ù… Ù…ÙˆÙÙ‚ Ø¨Ù‡ ØªÙˆÙ„ÛŒØ¯ Ù‚Ø·Ø¹Ù‡ Ù†Ø´Ø¯Ù†Ø¯.")
    return None, last_error

# --- START: ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
def main():
    if not GOOGLE_API_AVAILABLE:
        logging.critical("Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ google.generativeai Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
        sys.stdout.write(json.dumps({"success": False, "error": "Ø®Ø·Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø³Ø±ÙˆØ±: Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø§ØµÙ„ÛŒ TTS ÛŒØ§ÙØª Ù†Ø´Ø¯."}))
        sys.exit(1)

    _init_api_keys()

    try:
        input_data = json.loads(sys.stdin.read())
    except json.JSONDecodeError:
        logging.error("Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† ÙˆØ±ÙˆØ¯ÛŒ JSON.")
        sys.stdout.write(json.dumps({"success": False, "error": "ÙˆØ±ÙˆØ¯ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±."}))
        sys.exit(1)

    text_input = input_data.get("text")
    prompt_input = input_data.get("prompt")
    selected_voice = input_data.get("speaker")
    temperature_val = input_data.get("temperature")
    session_id = input_data.get("session_id", str(uuid.uuid4())[:8])

    logging.info(f"[{session_id}] ğŸš€ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¬Ø¯ÛŒØ¯ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: Ú¯ÙˆÛŒÙ†Ø¯Ù‡={selected_voice}, Ø¯Ù…Ø§={temperature_val}")
    
    temp_dir = f"temp_{session_id}"
    os.makedirs(temp_dir, exist_ok=True)
    
    output_base_name = os.path.join(temp_dir, f"audio_session_{session_id}")

    try:
        if not text_input or not text_input.strip():
            raise ValueError("Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯.")

        text_chunks = smart_text_split(text_input, DEFAULT_MAX_CHUNK_SIZE)
        if not text_chunks:
            raise ValueError("Ù…ØªÙ† Ù‚Ø§Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡ Ù‚Ø·Ø¹Ø§Øª Ú©ÙˆÚ†Ú©ØªØ± Ù†ÛŒØ³Øª.")

        generated_files = []
        for i, chunk in enumerate(text_chunks):
            logging.info(f"[{session_id}] ğŸ”Š Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‚Ø·Ø¹Ù‡ {i+1}/{len(text_chunks)}...")
            
            # **ØªØºÛŒÛŒØ±:** Ù…Ø§ voice Ø±Ø§ Ø¨Ù‡ ØªØ§Ø¨Ø¹ Ù…ÛŒâ€ŒÙØ±Ø³ØªÛŒÙ… Ø§Ù…Ø§ Ø¯Ø± Ú©Ø¯ Ø¬Ø¯ÛŒØ¯ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….
            # Ù…Ø¯Ù„ Ø¨Ø§ÛŒØ¯ voice Ø±Ø§ Ø§Ø² prompt ØªØ´Ø®ÛŒØµ Ø¯Ù‡Ø¯ ÛŒØ§ Ø§Ø² ÛŒÚ© Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ø¯.
            inline_data, error_message = generate_audio_chunk_with_retry(chunk, prompt_input, selected_voice, temperature_val, session_id)
            
            if inline_data:
                data_buffer = inline_data.data
                ext = ".wav" 
                fname_base = f"{output_base_name}_part{i+1:03d}"
                fpath = save_binary_file(f"{fname_base}{ext}", data_buffer)
                if fpath: 
                    generated_files.append(fpath)
                else:
                    raise IOError(f"Ù…ÙˆÙÙ‚ Ø¨Ù‡ Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù‚Ø·Ø¹Ù‡ {i+1} Ù†Ø´Ø¯ÛŒÙ….") 
            else:
                raise Exception(f"ØªÙˆÙ„ÛŒØ¯ Ù‚Ø·Ø¹Ù‡ {i+1} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. Ø¢Ø®Ø±ÛŒÙ† Ø®Ø·Ø§ÛŒ Ø«Ø¨Øª Ø´Ø¯Ù‡: {error_message}")
            
            if i < len(text_chunks) - 1 and len(text_chunks) > 1: 
                time.sleep(DEFAULT_SLEEP_BETWEEN_REQUESTS)

        if not generated_files:
            raise Exception("Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯.")
        
        final_output_path = f"output_{session_id}.wav" 

        if len(generated_files) > 1:
            logging.info(f"[{session_id}] ğŸ–‡ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¯ØºØ§Ù… {len(generated_files)} Ù‚Ø·Ø¹Ù‡ ØµÙˆØªÛŒ...")
            if not merge_audio_files_func(generated_files, final_output_path):
                logging.warning(f"[{session_id}] âŒ Ø§Ø¯ØºØ§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. ÙÙ‚Ø· Ø§ÙˆÙ„ÛŒÙ† Ù‚Ø·Ø¹Ù‡ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
                shutil.copy(generated_files[0], final_output_path)
        else:
            shutil.copy(generated_files[0], final_output_path)
        
        if not os.path.exists(final_output_path):
            raise IOError("ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
            
        logging.info(f"[{session_id}] âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: {final_output_path}")
        sys.stdout.write(json.dumps({"success": True, "audio_file_path": final_output_path}))

    except Exception as e:
        logging.error(f"[{session_id}] âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± ÙØ±Ø¢ÛŒÙ†Ø¯ TTS: {e}")
        sys.stdout.write(json.dumps({"success": False, "error": str(e)}))
        sys.exit(1)
    finally:
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
            logging.info(f"[{session_id}] ğŸ§¹ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ù…ÙˆÙ‚Øª '{temp_dir}' Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø´Ø¯.")

if __name__ == "__main__":
    main()
